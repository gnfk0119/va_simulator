# VA Simulator (가상 스마트홈 생성기 및 행동 평가 시스템)

본 프로젝트는 가족 구성원의 행동 타임라인을 시뮬레이션하고, 이에 따른 스마트홈 음성 비서(VA)와의 상호작용 결과를 **1인칭(발화자)**과 **3인칭(관찰자)** 시점에서 듀얼 평가하기 위한 연구용 시스템입니다.

---

## 🚀 시작하기 (Getting Started)

### 의존성 설치
본 프로젝트는 Python 3.12를 권장합니다. 의존성 패키지는 아래 명령어로 설치할 수 있습니다:
```bash
pip install -r requirements.txt
```

### 실행 파이프라인
프로젝트는 크게 3단계의 파이프라인으로 구성되어 있으며, `main.py`를 통해 실행 제어가 가능합니다.

```bash
# 1. 환경 및 가족 스케줄 생성 (최초 실행)
python main.py --mode generate

# 2. 7일 타임라인 기반 15분 간격 시뮬레이션 본게임 진행
python main.py --mode simulate

# 3. 관찰자 시점 평가 수행 및 3종 엑셀 추출
python main.py --mode evaluate
```

> **💡 TIP:** 다수의 가구를 연속으로 시뮬레이션하고 싶다면, `config.yaml` 파일 내의 `num_profiles` 숫자를 늘린 뒤 아래 명령어로 전체 파이프라인을 한 번에 실행하세요.
> ```bash
> python main.py --mode all
> ```

---

## 🧠 시스템 핵심 아키텍처 및 작동 알고리즘

시뮬레이터는 **생성(Generate) ➔ 시뮬레이션(Simulate) ➔ 평가(Evaluate) ➔ 엑셀 추출(Export)** 의 4단계 알고리즘 흐름을 가집니다.

### 단계 1: 데이터 생성 (`generate` 모드)
`src/generator.py`에서 담당합니다.
*   **아파트 환경 구축:** 4가지 평면도 타입(Type A~D) 중 임의의 하나를 선택해 거실, 주방, 침실 등에 필수/선택 IoT 가전을 배치합니다. (`environment.json`)
*   **가구원 및 스케줄 배정 (Pandas 필터링):** 통계청 '생활시간조사' 데이터를 바탕으로 가족 구성원(ex. 40대 가장, 고등학생 자녀)의 특성에 맞는 **1주일 치 1시간 단위 기본 스케줄**을 구성합니다. 가족 구성원 외의 '환각' 인물이 포함되지 않도록 Profile 정보를 기반으로 엄격하게 통제합니다. (`family_profile.json`)

### 단계 2: 15분 단위 동기화 시뮬레이션 (`simulate` 모드)
`src/simulator.py` 내의 `SimulationEngine`에서 담당합니다.
*   **시간 쪼개기 및 정렬 (Timeline):** 생성된 1시간 단위 대분류 스케줄을 `0분, 15분, 30분, 45분`의 15분 간격 타임라인으로 분할하고, 전 가구원의 일정을 시간순으로 정렬합니다.
*   **공유 메모리 브로드캐스팅 (Shared Memory):**
    * 특정 가구원이 집 안에서 하는 **'구체적 행동(Concrete Action)'**은 로그북(메모리 시스템)에 기록됩니다.
    * 텔레파시처럼 내면의 생각이 완벽히 공유되는 것이 아니라, 다른 가구원들은 오직 이 "관찰 가능한 상태" 정보만을 맥락으로 파악하게 됩니다.
    * 메모리는 1시간이 지날 때마다 신뢰성(중요도) 가중치가 0.05씩 감소하며, 최저 0.3까지 떨어지는 감쇠(Decay) 로직이 반영되어 있습니다.
*   **잠재 명령 확보 및 이중(Dual) 명령 생성:**
    1.  현재 상황과 가족 상태 메모리를 융합하여, 사용자의 내면적 요구사항이 반영된 **`잠재 명령(Latent Command)`**를 도출합니다. (예: "더우니까 거실 에어컨 좀 켜줘")
    2.  이 잠재 명령을 바탕으로 2가지 형태의 VA 호출 명령어를 생성하여 독립된 테스트베드에서 실행합니다.
        *   ✅ **Context O (맥락 포함):** "아기가 자고 있어서 조용히 영상을 보고 싶으니 거실 TV 켜줘"
        *   ❌ **Context X (맥락 미포함):** "거실 TV 켜줘"
*   **초기 1인칭 만족도 평가 (Self Rating):** 사용자(아바타) 본인은 VA의 응답과 기기 조작 상태를 보고, 본인의 진짜 의도(잠재 명령)를 얼마나 채워주었는지 스스로 1~7점으로 채점합니다.

### 단계 3: 제 3자 관찰자 이중 평가 (`evaluate` 모드)
`src/evaluator.py`에서 담당합니다.
*   **정보 마스킹 (Information Masking):** 평가 모드에서 LLM은 시스템 로그나 음성 기록만 열람하는 **제 3자 관찰자(Observer)**가 됩니다. 따라서 사용자의 진짜 목적(`Latent Command`)은 물론, 사용자가 집 안에서 취한 구체적 행동조차 완전히 마스킹됩니다.
*   **관찰자 평가 (Observer Rating):** 관찰자는 오직 아래 2가지 단서만으로 VA의 대처 상황을 평가(1~7점)합니다. 이것 또한 `Context O / X` 2가지 로그 버전에 대해 별도로 평가합니다.
    1.  사용자가 VA에게 건넨 실제 음성 명령어 문장 및 응답
    2.  모든 기기 상태 변화 (`State Change`)

### 단계 4: 결과물 변환 및 추출 (`export` 과정)
`src/exporter.py`에서 담당하며, `evaluate` 모드가 완료되면 종속되어 자동 실행됩니다.
*   평가가 완료된 JSON 로그(`evaluation_result.json`)들을 파싱하여, 분석에 직관적인 형태의 **3가지 엑셀 파일** 로 내보냅니다. 결과물은 `data/exports/run_*` 와 같은 폴더명으로 각각 저장됩니다.
    *   `1_family_info.xlsx`: 참여 가족 멤버별 정보 요약 시트
    *   `2_memory_history.xlsx`: 가족 전원의 관찰 행동과 감쇠 가중치가 담긴 15분 간격 통합 로그 보드
    *   `3_interaction_history.xlsx`: 이중 발화 및 제어 로그, 1인칭/3인칭 평가사유가 모두 포함된 전체 상호작용 기록 마스터 시트
